# Auto Tasks

So we're given up the pretension of running something vaguely within the orbit of an actual scientific test with measurable results for this report
and default to simple logging and note taking.

What I want to observe is how well the application takes to attempting individual software tasks/tickets.
I also want to see the utility of the Auto workflow for large numbers of files. Put my claim that it can run 'arbitrarily' many operations to the test.

To these ends I have included 20+ files in an auto workflow operation, each one pre-pended with a task, covering almost all existent planned features in the README.
I want to see where it fails, and it will fail, almost certainly, but where and why are useful to know for optimising the application.
For improving its ability to solve any given problem given to it.
Currently we know it struggles with complexity and most of these features (bar a few) are rather complex, but how can we reduce and ease this complexity?

If it can successfully implement even 20% of the pages included that's ~4 features. That's almost an entire update right there.

| file                                         | 1 - Review Task | 2 - Attempt task |
|----------------------------------------------|-----------------|------------------|
| AiOrchestrator_RerunLogic.py                 | ‚ùå               | ‚úÖ                |
| Augmentation_AutoSelectPersona.py            | ‚ùé               | ‚úÖ                |
| Augmentation_AutoSelectWorkflow.py           | ‚ùé               | ‚úÖ                |
| AutoWorkflow_BossPersonaAttempt.py           | ‚úî               | ‚ùå                |
| AutoWorkflow_loopWorkflow.py                 | ‚úî               | ‚úÖ                |
| AutoWorkflow_ParallelProcessing.py           | ‚úî               | ‚úÖ                |
| CategoryManagement_AutomaticColourisation.py | ‚úî               | ‚úÖ                |
| CategoryManagement_categoryDescription.py    | ‚úî               | ‚úÖ                |
| ChatGptWrapper_RemoveReceipts.py             | ‚úî               | ‚úî                |
| InternetSearch.py                            | ‚úî               | ‚úÖ                |
| Messages_rewrite.js                          | ‚úî               | ‚úÖ                |
| Messages.js                                  | ‚ùé               | ‚úÖ                |
| NodeDatabaseManagement_EditGetCategory.py    | ‚úî               | ‚úÖ                |
| process_message_ws_modularWorkflows.py       | ‚úî               | ‚ùå                |
| S3Manager_ManageFileRevisions.py             | ‚úî               | ‚úñ Cancelled      |
| SugestedQuestions_MobileFriendly.js          | ‚ùé               | ‚ùå                |
| UserContextManagement_ExistingContext.py     | ‚úî               | ‚úî                |
| UserContextManagement_NodeDescription.py     | ‚úî               | ‚úñ Cancelled      |
| UserInputForm_Deselect.js                    | ‚úî               | ‚úÖ                |
| WriteWorkflow_AddGithubIntegration.py        | ‚úî               | ‚úñ Cancelled      |
| WriteWorkflow_CompileCheck.py                | -               | ‚úñ Cancelled      |
| WriteWorkflow_ModularWorkflows.py            | üÜó              | ‚úñ Cancelled      |
| WriteWorkflow_PhysicsMathIntegration.py      | üÜó              | ‚úñ Cancelled      |
| Writing_ExtensionCheck.py                    | ‚úî               | ‚úÖ                |


### 1 - Review Task

First stage is running auto on gpt-4o-mini and asking it if it thinks the task is possible, if it can improved and clarified,
and if any superfluous information can be removed.
The real purpose of this step is just to ensure that auto can execute a large payload of files without imploding in on top of itself
when running an actually expensive model.

Which it can.

| file                                         | Review                                                                                                                                                                                     |
|----------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| AiOrchestrator_RerunLogic.py                 | ‚ùå Not a useful response. First created answer. Again points to the idea that sequential history context helps clue it in.                                                                  |
| Augmentation_AutoSelectPersona.py            | ‚ùé Ditto, it's not familiar with the idea of using custom code to talk to a llm even if told to write such.                                                                                 |
| Augmentation_AutoSelectWorkflow.py           | ‚ùé Wrong but lays the solution for a correct solution                                                                                                                                       |
| AutoWorkflow_BossPersonaAttempt.py           | ‚úî A basic layout and yes, a misunderstanding of the requirements. But it can be built upon                                                                                                 |
| AutoWorkflow_loopWorkflow.py                 | ‚úî This might be just straight up solved, really consistent solution                                                                                                                        |
| AutoWorkflow_ParrallelProcessing.py          | ‚úî Stripped the iteration from parallel processing. This makes sense without context, but is required to ensure the frontend workflow displays                                              |
| CategoryManagement_AutomaticColourisation.py | ‚úî I think this is also an example of the benefit of sequential calls, the llm already had a version of categoryManagement.py in its history even though this wasn't supplied in the prompt |
| CategoryManagement_categoryDescription.py    | ‚úî I suppose a lot of these are just easier than I imagined.                                                                                                                                |
| ChatGptWrapper_RemoveReceipts.py             | ‚úî Needed to update, as the solution it gave wasn't exactly what I was thinking. Could have explained myself clearer                                                                        |
| InternetSearch.py                            | ‚úî                                                                                                                                                                                          |
| Messages_rewrite.js                          | ‚úî Ahhhh, that was easier than I thought it was                                                                                                                                             |
| Messages.js                                  | ‚ùé Only did messages, but understandable given how much content is present. <br/>Have refactored to make borrowing from app.js component more obvious                                       |
| NodeDatabaseManagement_EditGetCategory.py    | ‚úî This is an embarassement of riches                                                                                                                                                       |
| process_message_ws_modularWorkflows.py       | ‚úî Perfectly plausible solution.                                                                                                                                                            |
| S3Manager_ManageFileRevisions.py             | ‚úî Perfectly plausible solution.                                                                                                                                                            |
| SugestedQuestions_MobileFriendly.js          | ‚ùé Our first misunderstanding (finally). I've expanded on the task description to make it less ambigous                                                                                     |
| UserContextManagement_ExistingContext.py     | ‚úî Perfectly plausible solution.                                                                                                                                                            |
| UserContextManagement_NodeDescription.py     | ‚úî Perfectly plausible solution. Needs re-writing to integrate with the application, but that's expected                                                                                    |
| UserInputForm_Deselect.js                    | ‚úî I might have overestimated how hard this task was                                                                                                                                        |
| WriteWorkflow_AddGithubIntegration.py        | ‚úî This is a pretty plausible solution. I would still like o1-mini to attempt the task though                                                                                               |
| WriteWorkflow_CompileCheck.py                | a solution, but I don't like having to save the file to check it compiles                                                                                                                  |
| WriteWorkflow_ModularWorkflows.py            | üÜó Actually tried to attempt the solution, not surprising, 4o-mini gets confused easily, but still might be useful                                                                         |
| WriteWorkflow_PhysicsMathIntegration.py      | üÜó A plausible *format* for a solution but the methods aren't filled out.                                                                                                                  |
| Writing_ExtensionCheck.py                    | ‚úî  Plausibly this has been solved in the review task stage, an easy task though so not surprising                                                                                          |

So this did *surprisingly* well, I expected the expensive models like o1-mini to be confused and just produce garbage. But the vast majority of content output is useful *to some degree*.
It *did* fail at actually analysing the task itself on a meta level and suggesting improvements to the task file without doing the task itself.
But its been said before:

The words "Do NOT actually try and answer this task" contain the words " try and answer this task"

### 2 - Attempt Task

Completed @16:36 2025/01/13
Cost: $4.93 (Well the good news is that the openAi billing and your own estimates match almost exactly)

That's very high cost, I anticipated 2-3 euro. Though, the previous large workflow cost about this but ran for only 11 files. 
ToDo: Check the logs to ensure tokens aren't being wasted somewhere.
(in typical fashion the o1-responses are twice as long, which explains why they cost 30 x 2 times more than than the gpt-4-mini responses)
(also in the last response with the issue with ALL file references being sent to each individual step, input costs where 1.5x times higher than output costs, 
here they're 0.9x)

Now lets see what I got for my money.

| file                                         | Review                                                                                                                                                                                                                                                                                                                       |
|----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| AiOrchestrator_RerunLogic.py                 | ‚≠ê‚≠ê‚≠ê Lots of work needed to adapt, 2 errors: first it replaced the default behaviour, instead of creating a switch not so bad, but secondly it removed the last step for comparing responses, neutering the feature.                                                                                                          |
| Augmentation_AutoSelectPersona.py            | ‚≠ê‚≠ê‚≠ê‚≠ê Similar to AutoSelectWorkflow, except I could use that for reference. Funnily enough placeholder I laid at the start for automated persona selection won't quite work I don't think. A problem for later                                                                                                                |
| Augmentation_AutoSelectWorkflow.py           | ‚≠ê‚≠ê‚≠ê Backend component worked great. In future you will also have to ask for the *frontend* changes as well, which where the majority of the work here. In general I think you really need to go detail by detail, describing what you *think* needs to change                                                                |
| AutoWorkflow_BossPersonaAttempt.py           | ‚ùå Not surprising, its a pretty hard task, likely I could have really added a lot more details as to what I wanted as its a very specific vision, but this simply isn't salvageable.                                                                                                                                          |
| AutoWorkflow_loopWorkflow.py                 | ‚≠ê‚≠ê‚≠ê Needed to be refactored to follow how I want my workflows structured but served as a good basis. Like a lot of requests would have been better if I included more, focused references (e.g. the workflows schema methods)                                                                                                |
| AutoWorkflow_ParallelProcessing.py           | ‚≠ê‚≠ê‚≠ê Had to be redesigned -due to trying to use contextVars while multi-threading within flask, passing the variables along it works fine (other than continually not understanding that I want _summary_step run itself not a string)                                                                                        |
| CategoryManagement_AutomaticColourisation.py | ‚≠ê‚≠ê‚≠ê The work I needed to do was taking the colour generating code and correcting the database handling code, the frontend code handling list category responses and the actual displaying of the new information                                                                                                             |
| CategoryManagement_categoryDescription.py    | ‚≠ê‚≠ê‚≠ê Only rating 3 stars because it took an hour+, but it wrote most of the necessary code. Could have benefited from knowing more about how CategoryManagement.py is used and less about CategoryMangement.py itself.                                                                                                        |
| ChatGptWrapper_RemoveReceipts.py             | ‚≠ê A lot of the poor score is in me realising I could update any node just by its UUID id parameter rather than trying to arbitrarily track different types of functionality. Instead scanning over the files and coming to a plan may have been more useful                                                                  |
| InternetSearch.py                            | ‚≠ê‚≠ê‚≠ê‚≠ê Worked with some minor modification, unfortunately the search engine I choose (duckduckgo - its free) and there instant search does not work well, so modifications had to be made.                                                                                                                                     |
| Messages_rewrite.js                          | ‚≠ê‚≠ê Already done (by bleeding in) to Messages.js. Did spend a notable amount of time there debugging due to the LLM changing a state variable to a set (which isn't passed from component to component and back)                                                                                                              |
| Messages.js                                  | ‚≠ê‚≠ê‚≠ê‚≠ê Works, I think the use of onFileSelect/onMessageSelect is a bit confused but it did manage to just copy the existing app.js jsx to its own page (so not that hard). Also appears to be some unwanted bleed-in from Messages_rewrite.js                                                                                  |
| NodeDatabaseManagement_EditGetCategory.py    | ‚≠ê‚≠ê‚≠ê‚≠ê Also has recommendations for the rest of the file, that are wasted. Definitely next time need to get it to laser focus on the task at hand                                                                                                                                                                              |
| process_message_ws_modularWorkflows.py       | ‚ùå It appears multithreading an entire application *within* a flask context passes the complexity barrier for even o1-preview and it just can't provide a working solution.                                                                                                                                                   |
| S3Manager_ManageFileRevisions.py             | ‚úñ Cancelled (Currently new files are registered when an existing node is overwritten, ACTUALLY it might be better to keep that 'feature' and just don't overwrite it, each node corresponds to one version.                                                                                                                  |
| SuggestedQuestions_MobileFriendly.js         | ‚ùå While the initial version actually fills the main requirements, it has crippling bugs which the AI cannot fix, I believe this issue is that it tries to adapt a users existing code, hyper-fixating on whats already present instead of creating a new valid approach, perhaps a workflow step could help with this issue? |
| UserContextManagement_ExistingContext.py     | ‚≠ê Added a bunch of methods I had no use for, did help me remember I had already made a 'list_user_topics' method and just needed to plug it in to context creation and retrieval.                                                                                                                                            |
| UserContextManagement_NodeDescription.py     | ‚úñ Cancelled (I've implemented changes in how the user memory node system works and now it might not be so useful to have node descriptions                                                                                                                                                                                   |
| UserInputForm_Deselect.js                    | ‚≠ê‚≠ê That tick only means I was able to implement the feature. Huge amounts of salvaging.                                                                                                                                                                                                                                      |
| WriteWorkflow_AddGithubIntegration.py        | ‚úñ Cancelled Would be three or four stars otherwise, my ideas for how any form of github integration takes place have changed, but being able to read which files exist in a given repo could be really useful down the line                                                                                                  |
| WriteWorkflow_CompileCheck.py                | ‚úñ Cancelled (If a file needs to make reference to other user files, as it will in the majority of cases when working on a project? It will fail needlessly)                                                                                                                                                                  |
| WriteWorkflow_ModularWorkflows.py            | ‚úñ Cancelled (See above. There could be a case made latter if a AI check was made to see if a code can and should be compiled but its not a priority currently.)                                                                                                                                                              |
| WriteWorkflow_PhysicsMathIntegration.py      | ‚úñ Cancelled (Not bad, but when faced with having to input a wolframalpha api id, its just *not* a priority at the current moment. Aside from that again more bleed in, compile checks where added where they really didn't need to be)                                                                                       |
| Writing_ExtensionCheck.py                    | ‚≠ê‚≠ê‚≠ê Works with some modification. Also suggests changes to the rest of the code. In future, the real part of this<br/> will be to somehow split out the exact code that's actually needed with cheap LLM's and feed the key, minimised info in for an expensive LLM                                                          |

While there's some evidence gpt-4-mini benefited from the extra context by having a memory of prior tasks, o4-mini did not. Frequent bleed in and confusion. Next time specifically tell it to focus on the task at hand not optimise.

So in light of being able to use every provided solution so far to at least take a shot at implementing the given task if not solve in the majority. I'm switch to a suitably imprecise 5 star review system to look for improvements.
5 stars means I needed to do nothing to implement the LLM's solution
1 star means its solution was almost completely useless and not a single line or idea could serve as inspiration in looking for the correct solution.

### Conclusion

So given that this kept me busy for 2 weeks, it was worth it. 
Many workflow steps also seems to have been laid astray by all the context fed into it from the prior tasks, this should be solved with the new ~~Auto~~ForEach workflow being run in parallel instead of sequentially. 
A lot of options have also had to change as my own thoughts have changed, partially by seeing a potential implementation in action. 
So the cancelled tasks aren't really a mark against it. The 3 failures are, but as mentioned in their sections, they *were* rather complex difficult tasks
(Also I might have kept going with these tasks instead of cancelling them but its high time I go to public beta and prioritise accordingly)

Total stars: 41

Average rating per un-cancelled ticket: 2.28

Implemented features: 10 / 18 -> 55%

Next time I would recommend specifically tailoring reference material for a task down, include relevant methods and constants not the whole file. 
Additionally include more references a common denominator would be the corresponding backend/frontend implementation for a primarily frontend/backend function.
