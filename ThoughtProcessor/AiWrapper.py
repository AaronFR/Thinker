import logging
from typing import List, Dict
import Constants
import Globals
from Prompter import Prompter
from Utility import Utility





class AiWrapper:
    """This class manages a single interaction with a llm. Each instance of 'Thought' is focused on
        understanding user input and generating an appropriate output based on that input."""

    def __init__(self, input_files: List[str]):
        """Initializes a llm wrapper instance that handles the interaction with the OpenAI API.

        :param input_files: A list of file names that users provide for analysis or reference in generating responses.
        :param prompter: An instance of the Prompter class, responsible for creating the prompts sent to the OpenAI API.
        :param open_ai_client: The OpenAI API client instance.
        """
        self.input_files = input_files

    def execute(self, system_prompts: List[str] | str, user_prompts: List[str] | str) -> str:
        """Generate a response based on system and user prompts.

        This method constructs messages to be sent to the OpenAI API and retrieves a response.
        ToDo: At some point actions other than writing will be needed, e.g. 'web search'
        ToDo: With large context lengths approx 5k+ the current executive prompt can fail to produce an actual json
         output and get confused into writing a unironic answer
        #Solved if executive files only review summaries of input files

        :param system_prompts: The system prompts to guide the thinking process.
        :param user_prompts: The user prompts representing supplied material and instructions
        :return: The response generated by OpenAI or an error message.
        """
        messages = Prompter.generate_messages(self.input_files, system_prompts, user_prompts)

        response = Utility.execute_with_retries(lambda: Globals.prompter.get_open_ai_response(messages))
        if not response:
            logging.error("No response from OpenAI API.")
            raise Exception("Failed to get response from OpenAI API.")

        logging.info(f"Executor Task Finished")
        return response

    def execute_function(self, system_prompts: List[str] | str, user_prompts: List[str], function_schema=Constants.EXECUTIVE_FUNCTIONS_SCHEMA) -> Dict[str, object]:
        """Generates a structured response based on system and user prompts for executive directives.
        ToDo: At some point actions other than writing will be needed, e.g. 'web search'
        #Solved if executive files only review summaries of input files

        :param system_prompts: The system prompts to guide the thinking process.
        :param user_prompts: The specific task to address.
        :return: The response generated by OpenAI or an error message.
        """
        messages = Prompter.generate_messages(self.input_files, system_prompts, user_prompts)

        response = Utility.execute_with_retries(lambda: Globals.prompter.get_open_ai_function_response(messages, function_schema))
        if not response:
            logging.error("No response from OpenAI API.")
            raise Exception("Failed to get response from OpenAI API.")

        logging.info(f"Executive Task Finished")
        return response


if __name__ == '__main__':
    ai_wrapper = AiWrapper(["solution.txt"])

    print(ai_wrapper.execute(
        Constants.EXECUTIVE_SYSTEM_INSTRUCTIONS,
        """
        rewrite solution.txt to be more concise"""))

