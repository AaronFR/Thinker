import enum
import logging
import time
from pprint import pformat
from typing import List, Dict
from openai import OpenAI, OpenAIError
import Constants
from Prompter import Prompter
from Utility import Utility





class Thought:
    """Class to manage and process 'thoughts' in the Thinker system using the OpenAI API"""

    def __init__(self, input_files: List[str], prompter: Prompter, open_ai_client: OpenAI):
        """Each 'Thought' represents a single call to the api that then adds to the existing body of files representing
        a solution to the initial task that triggered the thought process.

        :param input_files: file references representing files passed in by the user for processing/reference
        :param prompter: handles prompting the OpenAi API
        :param open_ai_client: The OpenAI API client instance.
        """
        self.prompter = prompter
        self.open_ai_client = open_ai_client
        self.input_files = input_files

    def think(self, system_prompts: List[str], user_prompt: str) -> str:
        """Generate a response based on system and user prompts.
        ToDo: At some point actions other than writing will be needed, e.g. 'web search'
        ToDo: With large context lengths approx 5k+ the current executive prompt can fail to produce an actual json output and get confused into writing a unironic answer
        #Solved if executive files only review summaries of input files

        :param system_prompts: The system prompts to guide the thinking process.
        :param user_prompt: The task the thought process is to be dedicated to.
        :return: The response generated by OpenAI or an error message.
        """
        logging.info(f"Thinking...{user_prompt}")
        messages = Prompter.generate_role_messages(system_prompts, self.input_files, user_prompt)

        logging.debug(f"Messages: {messages}")
        logging.info(f"Tokens used (limit 128k): {Utility.calculate_tokens_used(messages)}")

        response = Utility.execute_with_retries(lambda: self.get_open_ai_response(messages))
        if not response:
            logging.error("No response from OpenAI API.")
            raise Exception("Failed to get response from OpenAI API.")

        logging.info(f"Thought finished")
        return response

    def get_open_ai_response(self, messages: List[dict]) -> str | None:
        """Request a response from the OpenAI API.

        :param messages: The system and user messages to send to the ChatGpt client
        :return: The content of the response from OpenAI or an error message to inform the next Thought.
        """
        try:
            logging.debug(f"Calling OpenAI API with messages: {messages}")
            response = self.open_ai_client.chat.completions.create(
                model=Constants.MODEL_NAME, messages=messages
            ).choices[0].message.content
            return response or "[ERROR: NO RESPONSE FROM OpenAI API]"
        except OpenAIError:
            logging.error(f"OpenAI API error:")
            raise
        except Exception:
            logging.error(f"Unexpected error")
            raise


if __name__ == '__main__':
    prompter = Prompter()
    openai = OpenAI()
    thought = Thought(["solution.txt"], prompter, openai)

    print(thought.think(
        Constants.EXECUTIVE_PROMPT,
        """
        Give me a history of India"""))
        #"How can the Thought.py be improved? Write an improved version"))
